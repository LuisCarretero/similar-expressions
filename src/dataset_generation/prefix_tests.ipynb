{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CONST]']\n",
      "[S -> '[CONST]']\n",
      "['[CONST]']\n",
      "[S -> '[CONST]']\n",
      "['add', '[CONST]', 'mul', '[CONST]', 'x1']\n",
      "[S -> 'add' S S, S -> '[CONST]', S -> 'mul' S S, S -> '[CONST]', S -> 'x1']\n",
      "['add', '[CONST]', 'mul', '[CONST]', 'exp', 'x1']\n",
      "[S -> 'add' S S, S -> '[CONST]', S -> 'mul' S S, S -> '[CONST]', S -> 'exp' S, S -> 'x1']\n",
      "['mul', '[CONST]', 'pow', 'x1', '[CONST]']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Grammar does not cover some of the input words: \"'pow'\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# prefix[1] = '[CONST]'\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(prefix)\n\u001b[0;32m---> 63\u001b[0m tree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[43m_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(tree\u001b[38;5;241m.\u001b[39mproductions())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/small-mutations/lib/python3.12/site-packages/nltk/parse/chart.py:1474\u001b[0m, in \u001b[0;36mChartParser.parse\u001b[0;34m(self, tokens, tree_class)\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens, tree_class\u001b[38;5;241m=\u001b[39mTree):\n\u001b[0;32m-> 1474\u001b[0m     chart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchart_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(chart\u001b[38;5;241m.\u001b[39mparses(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grammar\u001b[38;5;241m.\u001b[39mstart(), tree_class\u001b[38;5;241m=\u001b[39mtree_class))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/small-mutations/lib/python3.12/site-packages/nltk/parse/chart.py:1432\u001b[0m, in \u001b[0;36mChartParser.chart_parse\u001b[0;34m(self, tokens, trace)\u001b[0m\n\u001b[1;32m   1429\u001b[0m trace_new_edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_new_edges\n\u001b[1;32m   1431\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tokens)\n\u001b[0;32m-> 1432\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grammar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_coverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1433\u001b[0m chart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chart_class(tokens)\n\u001b[1;32m   1434\u001b[0m grammar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grammar\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/small-mutations/lib/python3.12/site-packages/nltk/grammar.py:665\u001b[0m, in \u001b[0;36mCFG.check_coverage\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m    664\u001b[0m     missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m missing)\n\u001b[0;32m--> 665\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    666\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrammar does not cover some of the \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput words: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m missing\n\u001b[1;32m    667\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Grammar does not cover some of the input words: \"'pow'\"."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from nltk import CFG, Nonterminal, ChartParser\n",
    "import re\n",
    "\n",
    "grammar = \"\"\"\n",
    "S -> 'mul' S S\n",
    "S -> 'sub' S S\n",
    "S -> 'add' S S\n",
    "S -> 'div' S S\n",
    "S -> 'sin' S\n",
    "S -> 'exp' S\n",
    "S -> 'x1'\n",
    "S -> '[CONST]'\n",
    "Nothing -> None\"\"\"\n",
    "\n",
    "GCFG = CFG.fromstring(grammar)\n",
    "\n",
    "S, T = Nonterminal('S'), Nonterminal('T')\n",
    "\n",
    "def get_mask(nonterminal, grammar, as_variable=False):\n",
    "    if isinstance(nonterminal, Nonterminal):\n",
    "        mask = [rule.lhs() == nonterminal for rule in grammar.productions()]\n",
    "        mask = Variable(torch.FloatTensor(mask)) if as_variable else mask\n",
    "        return mask\n",
    "    else:\n",
    "        raise ValueError('Input must be instance of nltk.Nonterminal')\n",
    "\n",
    "\n",
    "pattern = r'-?\\b(?:\\d+(?:\\.\\d*)?|\\.\\d+)(?:[eE][-+]?\\d+)?\\b'\n",
    "consts = []\n",
    "\n",
    "def replace_and_collect(match):\n",
    "    consts.append(match.group())\n",
    "    return '[CONST]'\n",
    "\n",
    "_productions = GCFG.productions()\n",
    "_parser = ChartParser(GCFG)\n",
    "_prod_map = {prod: idx for idx, prod in enumerate(_productions)}\n",
    "\n",
    "\n",
    "eq = 'exp(x1*exp(0.998916506767273))'\n",
    "\n",
    "from utils import create_generator\n",
    "import sympy as sp\n",
    "\n",
    "\n",
    "datapath = r'/Users/luis/Desktop/Cranmer 2024/Workplace/smallMutations/similar-expressions/data/expr_240811_1.txt'\n",
    "with open(datapath, 'r') as f:\n",
    "    eqs = f.readlines()\n",
    "    eqs = [eq.strip('\\n') for eq in eqs]\n",
    "\n",
    "for eq in eqs[:10]:\n",
    "    gen, params = create_generator('./data_settings.json')\n",
    "\n",
    "    expr = sp.simplify(eq)\n",
    "    prefix = gen.sympy_to_prefix(expr)\n",
    "    # print(prefix)\n",
    "    prefix = [re.sub(pattern, replace_and_collect, token) for token in prefix]\n",
    "    # prefix[1] = '[CONST]'\n",
    "    print(prefix)\n",
    "\n",
    "    tree = next(_parser.parse(prefix))\n",
    "    print(tree.productions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,168.0,168.0\" width=\"168px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"14.2857%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">*</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.14286%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"42.8571%\" x=\"14.2857%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">[CONST]</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"35.7143%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"42.8571%\" x=\"57.1429%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"55.5556%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">sin</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"27.7778%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"44.4444%\" x=\"55.5556%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">x1</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"77.7778%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"78.5714%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', ['*', Tree('S', ['[CONST]']), Tree('S', ['sin', Tree('S', ['x1'])])])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 2, 6, 22, 90, 394, 1806, 8558, 41586, 206098],\n",
       " [1, 4, 16, 68, 304, 1412, 6752, 33028, 164512],\n",
       " [1, 6, 30, 146, 714, 3534, 17718, 89898],\n",
       " [1, 8, 48, 264, 1408, 7432, 39152],\n",
       " [1, 10, 70, 430, 2490, 14002],\n",
       " [1, 12, 96, 652, 4080],\n",
       " [1, 14, 126, 938],\n",
       " [1, 16, 160],\n",
       " [1, 18],\n",
       " [1]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ops = 5\n",
    "nl = 1\n",
    "p1 = 1\n",
    "p2 = 1\n",
    "\n",
    "D = []\n",
    "D.append([0] + ([nl ** i for i in range(1, 2 * max_ops + 1)]))\n",
    "for n in range(1, 2 * max_ops + 1):  # number of operators\n",
    "    s = [0]\n",
    "    for e in range(1, 2 * max_ops - n + 1):  # number of empty nodes\n",
    "        s.append(\n",
    "            nl * s[e - 1]\n",
    "            + p1 * D[n - 1][e]\n",
    "            + p2 * D[n - 1][e + 1]\n",
    "        )\n",
    "    D.append(s)\n",
    "assert all(len(D[i]) >= len(D[i + 1]) for i in range(len(D) - 1))\n",
    "D = [\n",
    "    [D[j][i] for j in range(len(D)) if i < len(D[j])]\n",
    "    for i in range(max(len(x) for x in D))\n",
    "]\n",
    "\n",
    "ubi_dist = D\n",
    "ubi_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _sample_next_pos_ubi(nb_empty, nb_ops, rng):\n",
    "    \"\"\"\n",
    "    Sample the position of the next node (unary-binary case).\n",
    "    Sample a position in {0, ..., `nb_empty` - 1}, along with an arity.\n",
    "    \"\"\"\n",
    "    assert nb_ops > 0\n",
    "    assert nb_empty > 0\n",
    "    probs = []\n",
    "    for i in range(nb_empty):\n",
    "        probs.append(\n",
    "            (nl ** i) * p1 * ubi_dist[nb_empty - i][nb_ops - 1]\n",
    "        )\n",
    "    for i in range(nb_empty):\n",
    "        probs.append(\n",
    "            (nl ** i) * p2 * ubi_dist[nb_empty - i + 1][nb_ops - 1]\n",
    "        )\n",
    "    probs = [p / ubi_dist[nb_empty][nb_ops] for p in probs]\n",
    "    probs = np.array(probs, dtype=np.float64)\n",
    "    e = rng.choice(2 * nb_empty, p=probs)\n",
    "    arity = 1 if e < nb_empty else 2\n",
    "    e = e % nb_empty\n",
    "    return e, arity\n",
    "\n",
    "e, arity = _sample_next_pos_ubi(5, 2, np.random.default_rng())\n",
    "e, arity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "['div', None, None]\n",
      "4\n",
      "['div', None, 'sub', None, None]\n",
      "3\n",
      "['div', None, 'sub', 'add', None, None, None]\n",
      "2\n",
      "['div', None, 'sub', 'add', None, None, 'add', None, None]\n",
      "1\n",
      "['div', None, 'sub', 'add', None, None, 'add', 'sin', None, None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['div', 'x1', 'sub', 'add', 'x1', 'c', 'add', 'sin', 'x1', 'x1']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import utils\n",
    "import generator\n",
    "reload(generator)\n",
    "reload(utils)\n",
    "from utils import create_generator\n",
    "import numpy as np\n",
    "\n",
    "gen, param = create_generator('./data_settings.json')\n",
    "\n",
    "gen._generate_expr(5, np.random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "small-mutations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
