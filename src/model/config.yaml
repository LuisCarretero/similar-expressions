model:
  encoder:
    size_hidden: 256
    architecture: residual-parameterized
    depth: 3
    width: 512
  z_size: 256
  decoder:
    z_slice: [0, -1]
    size_hidden: 128
    architecture: mlp-parameterized
    depth: 1
    width: 16
  value_decoder:
    z_slice: [0, -1]
    architecture: residual-parameterized
    depth: 3
    width: 512
  io_format:
    seq_len: 15
    token_cnt: 10
    val_points: 100

training:
  batch_size: 2048
  epochs: 200
  valid_split: 0.1
  dataset_len_limit: null
  criterion:
    ae_weight: 0.0
    kl_weight: 0
    syntax_weight: 0.5
    contrastive_weight: 0
  sampling:
    prior_std: 1
    eps: 0
  optimizer:
    lr: 5e-3
    clip: null
    scheduler_factor: 0.1
    scheduler_patience: 10
    scheduler_threshold: 2e-4
    scheduler_min_lr: 0
  performance_metric: train/loss
  kl_anneal:
    schedule: sigmoid
    midpoint: 0.4
    steepness: 15
  values_init_bias: false
  use_grammar_mask: false
